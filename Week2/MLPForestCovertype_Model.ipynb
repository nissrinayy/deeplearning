{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nissrinayy/deeplearning/blob/main/Week2/MLPForestCovertype_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tugas Week 2 Deep Learning ğŸš€ğŸš€**"
      ],
      "metadata": {
        "id": "qsmwgb6eHDvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Membuat model MLP menggunakan dataset Forest Cover Type:ğŸ¿**"
      ],
      "metadata": {
        "id": "FgoPaIXRHKPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "jtcWWfg4eu7r",
        "outputId": "3cd2f102-1aae-493b-ae31-ff01fbf6220c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41b1660f-0711-4e5c-9a4e-cb6bf1b12191\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41b1660f-0711-4e5c-9a4e-cb6bf1b12191\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving compressed_data.csv to compressed_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Install dan import LibraryğŸ”–**"
      ],
      "metadata": {
        "id": "mRd1XA-hH1-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IpYpzlrCgZUE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load & PreProcessing DatasetğŸ”**"
      ],
      "metadata": {
        "id": "xNx1n-cZH-bt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ldxSqOzPgqay"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"compressed_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7amlOz7icJz",
        "outputId": "8a669e02-68f8-42a4-c7b9-e91d867a95da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 581012 entries, 0 to 581011\n",
            "Data columns (total 55 columns):\n",
            " #   Column                              Non-Null Count   Dtype\n",
            "---  ------                              --------------   -----\n",
            " 0   Elevation                           581012 non-null  int64\n",
            " 1   Aspect                              581012 non-null  int64\n",
            " 2   Slope                               581012 non-null  int64\n",
            " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
            " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
            " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
            " 6   Hillshade_9am                       581012 non-null  int64\n",
            " 7   Hillshade_Noon                      581012 non-null  int64\n",
            " 8   Hillshade_3pm                       581012 non-null  int64\n",
            " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
            " 10  Wilderness_Area1                    581012 non-null  int64\n",
            " 11  Soil_Type1                          581012 non-null  int64\n",
            " 12  Soil_Type2                          581012 non-null  int64\n",
            " 13  Soil_Type3                          581012 non-null  int64\n",
            " 14  Soil_Type4                          581012 non-null  int64\n",
            " 15  Soil_Type5                          581012 non-null  int64\n",
            " 16  Soil_Type6                          581012 non-null  int64\n",
            " 17  Soil_Type7                          581012 non-null  int64\n",
            " 18  Soil_Type8                          581012 non-null  int64\n",
            " 19  Soil_Type9                          581012 non-null  int64\n",
            " 20  Soil_Type10                         581012 non-null  int64\n",
            " 21  Soil_Type11                         581012 non-null  int64\n",
            " 22  Soil_Type12                         581012 non-null  int64\n",
            " 23  Soil_Type13                         581012 non-null  int64\n",
            " 24  Soil_Type14                         581012 non-null  int64\n",
            " 25  Soil_Type15                         581012 non-null  int64\n",
            " 26  Soil_Type16                         581012 non-null  int64\n",
            " 27  Soil_Type17                         581012 non-null  int64\n",
            " 28  Soil_Type18                         581012 non-null  int64\n",
            " 29  Soil_Type19                         581012 non-null  int64\n",
            " 30  Soil_Type20                         581012 non-null  int64\n",
            " 31  Soil_Type21                         581012 non-null  int64\n",
            " 32  Soil_Type22                         581012 non-null  int64\n",
            " 33  Soil_Type23                         581012 non-null  int64\n",
            " 34  Soil_Type24                         581012 non-null  int64\n",
            " 35  Soil_Type25                         581012 non-null  int64\n",
            " 36  Soil_Type26                         581012 non-null  int64\n",
            " 37  Soil_Type27                         581012 non-null  int64\n",
            " 38  Soil_Type28                         581012 non-null  int64\n",
            " 39  Soil_Type29                         581012 non-null  int64\n",
            " 40  Soil_Type30                         581012 non-null  int64\n",
            " 41  Soil_Type31                         581012 non-null  int64\n",
            " 42  Soil_Type32                         581012 non-null  int64\n",
            " 43  Soil_Type33                         581012 non-null  int64\n",
            " 44  Soil_Type34                         581012 non-null  int64\n",
            " 45  Soil_Type35                         581012 non-null  int64\n",
            " 46  Soil_Type36                         581012 non-null  int64\n",
            " 47  Soil_Type37                         581012 non-null  int64\n",
            " 48  Soil_Type38                         581012 non-null  int64\n",
            " 49  Soil_Type39                         581012 non-null  int64\n",
            " 50  Soil_Type40                         581012 non-null  int64\n",
            " 51  Wilderness_Area2                    581012 non-null  int64\n",
            " 52  Wilderness_Area3                    581012 non-null  int64\n",
            " 53  Wilderness_Area4                    581012 non-null  int64\n",
            " 54  Cover_Type                          581012 non-null  int64\n",
            "dtypes: int64(55)\n",
            "memory usage: 243.8 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0bfEVaipLq",
        "outputId": "ae1148d1-eabe-4908-d457-93c8adf5beb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "0       2596      51      3                               258   \n",
            "1       2590      56      2                               212   \n",
            "2       2804     139      9                               268   \n",
            "3       2785     155     18                               242   \n",
            "4       2595      45      2                               153   \n",
            "\n",
            "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "0                               0                              510   \n",
            "1                              -6                              390   \n",
            "2                              65                             3180   \n",
            "3                             118                             3090   \n",
            "4                              -1                              391   \n",
            "\n",
            "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "0            221             232            148   \n",
            "1            220             235            151   \n",
            "2            234             238            135   \n",
            "3            238             238            122   \n",
            "4            220             234            150   \n",
            "\n",
            "   Horizontal_Distance_To_Fire_Points  Wilderness_Area1  Soil_Type1  \\\n",
            "0                                6279                 1           0   \n",
            "1                                6225                 1           0   \n",
            "2                                6121                 1           0   \n",
            "3                                6211                 1           0   \n",
            "4                                6172                 1           0   \n",
            "\n",
            "   Soil_Type2  Soil_Type3  Soil_Type4  Soil_Type5  Soil_Type6  Soil_Type7  \\\n",
            "0           0           0           0           0           0           0   \n",
            "1           0           0           0           0           0           0   \n",
            "2           0           0           0           0           0           0   \n",
            "3           0           0           0           0           0           0   \n",
            "4           0           0           0           0           0           0   \n",
            "\n",
            "   Soil_Type8  Soil_Type9  Soil_Type10  Soil_Type11  Soil_Type12  Soil_Type13  \\\n",
            "0           0           0            0            0            0            0   \n",
            "1           0           0            0            0            0            0   \n",
            "2           0           0            0            0            1            0   \n",
            "3           0           0            0            0            0            0   \n",
            "4           0           0            0            0            0            0   \n",
            "\n",
            "   Soil_Type14  Soil_Type15  Soil_Type16  Soil_Type17  Soil_Type18  \\\n",
            "0            0            0            0            0            0   \n",
            "1            0            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            0            0            0            0   \n",
            "4            0            0            0            0            0   \n",
            "\n",
            "   Soil_Type19  Soil_Type20  Soil_Type21  Soil_Type22  Soil_Type23  \\\n",
            "0            0            0            0            0            0   \n",
            "1            0            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            0            0            0            0   \n",
            "4            0            0            0            0            0   \n",
            "\n",
            "   Soil_Type24  Soil_Type25  Soil_Type26  Soil_Type27  Soil_Type28  \\\n",
            "0            0            0            0            0            0   \n",
            "1            0            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            0            0            0            0   \n",
            "4            0            0            0            0            0   \n",
            "\n",
            "   Soil_Type29  Soil_Type30  Soil_Type31  Soil_Type32  Soil_Type33  \\\n",
            "0            1            0            0            0            0   \n",
            "1            1            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            1            0            0            0   \n",
            "4            1            0            0            0            0   \n",
            "\n",
            "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "0            0            0            0            0            0   \n",
            "1            0            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            0            0            0            0   \n",
            "4            0            0            0            0            0   \n",
            "\n",
            "   Soil_Type39  Soil_Type40  Wilderness_Area2  Wilderness_Area3  \\\n",
            "0            0            0                 0                 0   \n",
            "1            0            0                 0                 0   \n",
            "2            0            0                 0                 0   \n",
            "3            0            0                 0                 0   \n",
            "4            0            0                 0                 0   \n",
            "\n",
            "   Wilderness_Area4  Cover_Type  \n",
            "0                 0           5  \n",
            "1                 0           5  \n",
            "2                 0           2  \n",
            "3                 0           2  \n",
            "4                 0           5  \n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IkI_3qImi4EJ"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Cover_Type'])\n",
        "y = df['Cover_Type']\n",
        "# Pastikan label mulai dari 0 (karena CrossEntropyLoss butuh label mulai dari 0)\n",
        "y = y - y.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M78TgtTYi6UI"
      },
      "outputs": [],
      "source": [
        "# Normalisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zxeaYreTjONn"
      },
      "outputs": [],
      "source": [
        "# Pisahkan data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model MLP dengan PyTorch**"
      ],
      "metadata": {
        "id": "ESMRxAV6IMji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l6iXP-oujVhn"
      },
      "outputs": [],
      "source": [
        "# Konversi data ke Tensor\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2XLXbwQcjZy0"
      },
      "outputs": [],
      "source": [
        "# Dataset dan DataLoader\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Oob7OfXgjtFe"
      },
      "outputs": [],
      "source": [
        "# Definisi Model\n",
        "class MLP_PyTorch(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_PyTorch, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u6NkuwuUjwEY"
      },
      "outputs": [],
      "source": [
        "# Model, Loss, dan Optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "output_dim = len(y.unique())\n",
        "\n",
        "model = MLP_PyTorch(input_dim, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCj4b0syj1tk",
        "outputId": "bc34e780-d2b7-44a7-d593-b0e980b59329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Loss: 0.2796\n",
            "Epoch 20/50, Loss: 0.2437\n",
            "Epoch 30/50, Loss: 0.2256\n",
            "Epoch 40/50, Loss: 0.2168\n",
            "Epoch 50/50, Loss: 0.2088\n"
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VZ6eLlimpzSI"
      },
      "outputs": [],
      "source": [
        "# Evaluasi Model PyTorch\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_pred.extend(predicted.numpy())\n",
        "        y_true.extend(y_batch.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOAWHR0rpzzE",
        "outputId": "b1b63ab9-b49b-42b9-b589-5eea11b57303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Model Evaluation:\n",
            "Accuracy: 0.9151\n",
            "Precision: 0.9150\n",
            "Recall: 0.9151\n",
            "F1-Score: 0.9148\n"
          ]
        }
      ],
      "source": [
        "# Hitung metrik evaluasi\n",
        "print(\"PyTorch Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yHBT8iSjp59T"
      },
      "outputs": [],
      "source": [
        "# ROC-AUC hanya bisa dihitung jika jumlah kelas = 2\n",
        "if output_dim == 2:\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model MLP dengan TensorFlow**"
      ],
      "metadata": {
        "id": "mCePJ3utIXLT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "J554djdfp6j4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "model_tf = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # âœ… Cara baru (lebih disarankan)\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(output_dim, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compile Model\n",
        "model_tf.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "VQmZMRhRsBhy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "model_tf.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv2pkIhasZHD",
        "outputId": "cfab73f9-2ee0-4476-ca7f-63d80bf81ebe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.5918 - val_accuracy: 0.8131 - val_loss: 0.4407\n",
            "Epoch 2/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4169 - val_accuracy: 0.8456 - val_loss: 0.3709\n",
            "Epoch 3/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3642 - val_accuracy: 0.8556 - val_loss: 0.3467\n",
            "Epoch 4/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3365 - val_accuracy: 0.8621 - val_loss: 0.3292\n",
            "Epoch 5/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.3200 - val_accuracy: 0.8694 - val_loss: 0.3174\n",
            "Epoch 6/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3061 - val_accuracy: 0.8777 - val_loss: 0.3002\n",
            "Epoch 7/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 0.2961 - val_accuracy: 0.8789 - val_loss: 0.2963\n",
            "Epoch 8/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2854 - val_accuracy: 0.8838 - val_loss: 0.2864\n",
            "Epoch 9/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.8864 - loss: 0.2795 - val_accuracy: 0.8842 - val_loss: 0.2837\n",
            "Epoch 10/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2732 - val_accuracy: 0.8878 - val_loss: 0.2755\n",
            "Epoch 11/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2663 - val_accuracy: 0.8861 - val_loss: 0.2832\n",
            "Epoch 12/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2626 - val_accuracy: 0.8890 - val_loss: 0.2751\n",
            "Epoch 13/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2585 - val_accuracy: 0.8914 - val_loss: 0.2713\n",
            "Epoch 14/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2557 - val_accuracy: 0.8967 - val_loss: 0.2574\n",
            "Epoch 15/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2493 - val_accuracy: 0.8933 - val_loss: 0.2639\n",
            "Epoch 16/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2478 - val_accuracy: 0.8934 - val_loss: 0.2607\n",
            "Epoch 17/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2465 - val_accuracy: 0.8964 - val_loss: 0.2515\n",
            "Epoch 18/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.2417 - val_accuracy: 0.8983 - val_loss: 0.2533\n",
            "Epoch 19/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2401 - val_accuracy: 0.9010 - val_loss: 0.2466\n",
            "Epoch 20/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2382 - val_accuracy: 0.9015 - val_loss: 0.2477\n",
            "Epoch 21/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2343 - val_accuracy: 0.8927 - val_loss: 0.2616\n",
            "Epoch 22/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2328 - val_accuracy: 0.9002 - val_loss: 0.2480\n",
            "Epoch 23/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2308 - val_accuracy: 0.9009 - val_loss: 0.2466\n",
            "Epoch 24/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2298 - val_accuracy: 0.9008 - val_loss: 0.2465\n",
            "Epoch 25/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2271 - val_accuracy: 0.9027 - val_loss: 0.2437\n",
            "Epoch 26/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2262 - val_accuracy: 0.9061 - val_loss: 0.2354\n",
            "Epoch 27/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2255 - val_accuracy: 0.9070 - val_loss: 0.2354\n",
            "Epoch 28/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2232 - val_accuracy: 0.8987 - val_loss: 0.2496\n",
            "Epoch 29/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2212 - val_accuracy: 0.9058 - val_loss: 0.2356\n",
            "Epoch 30/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2233 - val_accuracy: 0.8993 - val_loss: 0.2473\n",
            "Epoch 31/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2194 - val_accuracy: 0.9079 - val_loss: 0.2311\n",
            "Epoch 32/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2177 - val_accuracy: 0.9097 - val_loss: 0.2275\n",
            "Epoch 33/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2179 - val_accuracy: 0.9053 - val_loss: 0.2324\n",
            "Epoch 34/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2165 - val_accuracy: 0.9102 - val_loss: 0.2229\n",
            "Epoch 35/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2166 - val_accuracy: 0.9075 - val_loss: 0.2305\n",
            "Epoch 36/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2122 - val_accuracy: 0.9102 - val_loss: 0.2265\n",
            "Epoch 37/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2124 - val_accuracy: 0.9080 - val_loss: 0.2289\n",
            "Epoch 38/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2101 - val_accuracy: 0.9125 - val_loss: 0.2221\n",
            "Epoch 39/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2097 - val_accuracy: 0.9113 - val_loss: 0.2245\n",
            "Epoch 40/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2102 - val_accuracy: 0.9094 - val_loss: 0.2259\n",
            "Epoch 41/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2112 - val_accuracy: 0.9112 - val_loss: 0.2239\n",
            "Epoch 42/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2078 - val_accuracy: 0.9086 - val_loss: 0.2330\n",
            "Epoch 43/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2069 - val_accuracy: 0.9100 - val_loss: 0.2223\n",
            "Epoch 44/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2071 - val_accuracy: 0.9109 - val_loss: 0.2247\n",
            "Epoch 45/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2055 - val_accuracy: 0.9084 - val_loss: 0.2326\n",
            "Epoch 46/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2042 - val_accuracy: 0.8983 - val_loss: 0.2485\n",
            "Epoch 47/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2044 - val_accuracy: 0.9093 - val_loss: 0.2265\n",
            "Epoch 48/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2029 - val_accuracy: 0.9120 - val_loss: 0.2245\n",
            "Epoch 49/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2045 - val_accuracy: 0.9133 - val_loss: 0.2213\n",
            "Epoch 50/50\n",
            "\u001b[1m14526/14526\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2022 - val_accuracy: 0.9066 - val_loss: 0.2358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f792a9769d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi Model TensorFlow\n",
        "y_pred_probs = model_tf.predict(X_test)\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "print(\"TensorFlow Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In31hmfdEWTt",
        "outputId": "eedfaf02-60a6-4c79-cccd-fd2a78ab0ce1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3632/3632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "TensorFlow Model Evaluation:\n",
            "Accuracy: 0.9066\n",
            "Precision: 0.9099\n",
            "Recall: 0.9066\n",
            "F1-Score: 0.9059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC-AUC hanya bisa dihitung jika jumlah kelas = 2\n",
        "if output_dim == 2:\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_probs[:,1]):.4f}\")\n"
      ],
      "metadata": {
        "id": "2mnx_lJnEe-T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Penjelasan Singkat**\n",
        "\n",
        "1ï¸âƒ£ Akurasi (Accuracy)\n",
        "\n",
        "Akurasi mengukur seberapa banyak prediksi yang benar dibandingkan dengan total prediksi.\n",
        "\n",
        "Akurasi=\n",
        "\n",
        "TP+TN/ TP+TN+FP+FNâ€‹\n",
        "\n",
        "ğŸ“Œ Keterangan:\n",
        "\n",
        "TP (True Positive) â†’ Prediksi benar sebagai positif.\n",
        "\n",
        "TN (True Negative) â†’ Prediksi benar sebagai negatif.\n",
        "\n",
        "FP (False Positive) â†’ Prediksi salah sebagai positif.\n",
        "\n",
        "FN (False Negative) â†’ Prediksi salah sebagai negatif.\n",
        "\n",
        "2ï¸âƒ£ Presisi (Precision)\n",
        "\n",
        "Presisi mengukur seberapa akurat model dalam memprediksi kelas positif.\n",
        "\n",
        "Presisi= TP/ TP+FP\n",
        "\n",
        "ğŸ“Œ Keterangan:\n",
        "\n",
        "Jika model memiliki presisi tinggi, berarti model jarang salah dalam memprediksi kelas positif.\n",
        "\n",
        "Jika presisi rendah, model sering salah memprediksi negatif sebagai positif (False Positive tinggi).\n",
        "\n",
        "3ï¸âƒ£ Recall (Sensitivitas)\n",
        "\n",
        "Recall mengukur seberapa baik model dalam menangkap semua kasus positif.\n",
        "\n",
        "Recall= TP/ TP+FN\n",
        "\n",
        "ğŸ“Œ Keterangan:\n",
        "\n",
        "Jika recall tinggi, berarti model berhasil menangkap hampir semua data positif. Jika recall rendah, model sering gagal mengenali positif sebagai negatif (False Negative tinggi).\n",
        "\n",
        "4ï¸âƒ£ F1-Score (Harmonic Mean) F1-score menggabungkan presisi dan recall dalam satu metrik menggunakan rata-rata harmonik.\n",
        "\n",
        "ğ¹ 1 = 2 Ã— Presisi Ã— Recall/ Presisi + Recall\n",
        "\n",
        "ğŸ“Œ Keterangan:\n",
        "\n",
        "F1-score tinggi berarti model seimbang dalam presisi dan recall.\n",
        "\n",
        "Bagus untuk dataset tidak seimbang, karena mempertimbangkan False Positive dan False Negative secara bersamaan.\n",
        "\n",
        "5ï¸âƒ£ Area Under Curve (AUC - ROC) AUC (Area Under Curve) mengukur seberapa baik model membedakan antara kelas positif dan negatif.\n",
        "\n",
        "AUC berasal dari ROC Curve, yang membandingkan True Positive Rate (TPR) vs False Positive Rate (FPR).\n",
        "\n",
        "TPR = ğ‘‡ ğ‘ƒ/ ğ‘‡ ğ‘ƒ + ğ¹ ğ‘\n",
        "\n",
        "(Sama dengan Recall)\n",
        "\n",
        "FPR= FP/ FP+TN\n",
        "\n",
        "ğŸ“Œ Keterangan:\n",
        "\n",
        "AUC = 1.0 â†’ Model sempurna (memisahkan kelas dengan sempurna). AUC = 0.5 â†’ Model acak (tidak lebih baik dari tebak-tebakan). AUC < 0.5 â†’ Model lebih buruk dari acak (terbalik).\n",
        "\n",
        "6ï¸âƒ£ Receiver Operating Characteristic (ROC) Curve\n",
        "\n",
        "ROC Curve adalah grafik yang membandingkan TPR vs FPR pada berbagai threshold.\n",
        "\n",
        "Sumbu X â†’ FPR (False Positive Rate)\n",
        "\n",
        "Sumbu Y â†’ TPR (True Positive Rate / Recall)\n",
        "\n",
        "ğŸ“Œ Bagaimana membacanya?\n",
        "\n",
        "Semakin tinggi kurva, semakin baik model.\n",
        "\n",
        "ROC yang mendekati diagonal (AUC â‰ˆ 0.5) berarti model tidak berguna."
      ],
      "metadata": {
        "id": "zxB1huUtIfmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan**\n",
        "\n",
        "Model MLP ini performanya lebih baik saat dijalankan menggunakan Pytorch dengan selisih yang sangat kecil dengan Tensorflow.\n",
        "\n",
        "**Model Evaluasi Terbaik**\n",
        "\n",
        "Pada model MLP ini, Akurasi & F1-Score adalah metrik utama karena perbedaannya kecil antara Precision dan Recall."
      ],
      "metadata": {
        "id": "xxOAUobeFvJ-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvhVce+1PPgumpILUlqwcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}